# 반도체 장비 백업/버전 관리 최적 방안 (현재 인프라 기준)

---

## 1️⃣ 현재 인프라

- **장비 12대**
  - 로컬 디스크 2개 (1번 → 2번 하루 1회 백업)
  - 저장 데이터: pgm, 빌드 바이너리, 결과파일 (대략 300GB/장비)

- **서버**
  - 리눅스 4TB (장비 마운트 가능) → 실행/빌드 안정적, 용량 제한
  - 윈도우 서버 2대, 80TB RAID5, HA 구성, 1시간 단위 동기화 → 주 백업 저장소
  - dpms 백엔드 + DB 서버

---

## 2️⃣ 문제 요약

1. 로컬 디스크만 의존 → 포맷/삭제 사고 시 복구 불가  
2. NAS 논의 → 성능 저하, 단일 장애점, 비용/도입 기간 문제  
3. Git 도입 어려움 → 공용계정, 사용자 미숙련  
4. NFS 성능 문제 → 단순 파일 백업만 가능, 프로그램 실행 불가  
5. 리눅스 서버 4TB → 실행 안정적이지만 용량 부족

---

## 3️⃣ 제안 백업/버전 관리 절차

### 3.1 운영 원칙

- **실행/빌드/작업** → 장비 로컬 디스크 (I/O 성능 유지)  
- **백업/버전 관리** → dpms 증분 백업 + 윈도우 서버 저장  
- **임시/테스트 공유 공간** → 리눅스 4TB 서버 활용 (최근 데이터만, 오래된 데이터는 윈도우 서버로 이동)  
- **이력 관리** → dpms DB/hashcode 기반 버전 추적

### 3.2 백업 체계

| 구분          | 방법               | 대상               | 특징 |
|---------------|------------------|------------------|------|
| 1차 백업      | dpms 클라이언트   | 장비 12대         | 퇴근 전 수동 실행 or Makefile 자동 실행 가능 |
| 2차 저장      | dpms 서버 → 윈도우 서버 | RAID5 80TB ×2 HA  | 증분 백업, hashcode + DB 관리, 1시간 단위 동기화 |
| 임시 공유     | 리눅스 4TB       | 각 장비 마운트    | 실행/빌드 용도, 용량 한정 |

- dpms는 **metadata 기반 증분 전송** → tar + curl로 변경/추가 파일만 전송  
- 서버에서 **압축 + hashcode DB 저장** → Git과 유사한 버전 관리 기능 제공  
- 장비에서 바로 실행 가능한 **자동화 스크립트 포함** → 사용자 부담 최소화  

### 3.3 데이터 유형별 관리

| 데이터                 | 관리 방법             | 비고 |
|------------------------|--------------------|------|
| pgm / 빌드 스크립트    | dpms + Git 병행 가능  | 장기적으로 Git 도입 가능, 현재는 dpms로 이력 추적 |
| 결과 파일 (대용량)     | dpms 증분 백업       | Git 불필요, tar+curl로 효율적 |

### 3.4 장애 대응

1. **장비 로컬 디스크 포맷 사고** → dpms 서버에서 특정 시점 복원 가능  
2. **윈도우 서버 장애** → HA 구성으로 자동 전환, 1시간 동기화 기준 데이터 일부 손실 가능  
3. **네트워크 장애** → dpms 클라이언트에서 로컬 queue 저장 후 재전송 가능  

---

## 4️⃣ 권장 최적 플로우

1. **빌드 전/후 dpms 실행**
   - Makefile 통합 → 빌드 시 변경점 자동 전송

2. **장비/리눅스 서버 → 윈도우 서버 증분 백업**
   - Cron 하루 1회, 변경분만 전송
   - dpms hashcode + DB 기록

3. **윈도우 서버 HA + RAID5, DB replication**
   - 1시간 단위 동기화 → 서버 단일 장애 대비

4. **모니터링 + 알람 + 복구 시나리오**
   - 백업 성공/실패 로그, hashcode 무결성 확인

5. **장기 데이터 아카이브**
   - 오래된 결과 파일 → 압축/이관 → 스토리지 효율 확보

---

## 5️⃣ 추가 고려/보완 사항

| 구분                 | 보완 사항                                 | 이유 / 장점 |
|----------------------|------------------------------------------|-------------|
| 백업 주기             | Cron 1회 → 필요 시 장비별/파일별 증분 주기 조정 | 하루치 데이터 손실 가능성 최소화 |
| 복구 시나리오 문서화   | 각 사고 유형별 복구 절차 문서화           | 포맷, 장비 고장, 서버 HA 전환 등 대응력 확보 |
| 네트워크 장애 대비     | dpms 클라이언트 로컬 queue 기능 활성화    | 서버 접속 불가 시 재전송 가능 |
| 용량 관리             | 리눅스 4TB → 스테이징 용도 제한          | 실행 안정성과 용량 확보 |
| 모니터링/알람          | dpms 백업 성공/실패 알람 및 서버 상태 모니터링 | 장애 조기 감지, 운영 신뢰성 향상 |
| 데이터 무결성 확인     | dpms hashcode 기반 주기적 검증           | 전송/저장 과정 손상 확인 가능 |
| 보안/접근제어          | 장비별/사용자별 최소 권한, dpms 통신 암호화 | 데이터 유출 및 권한 문제 방지 |
| 장기 보관 정책         | 과거 데이터 보관 기간, 압축/아카이브 정책 수립 | 스토리지 효율, 법적/품질 요구사항 충족 |

---

## 6️⃣ 결론

- NAS 도입 없이도 현재 인프라만으로 **안정적 백업/복구 체계** 구축 가능  
- dpms + Cron + 윈도우 서버 HA 조합으로 사고 복구, 증분 백업, 버전 관리 모두 대응  
- 추가 보완: 모니터링, 용량 관리, 무결성 검증, 복구 시나리오 문서화  
- 장기적으로 pgm/빌드 스크립트는 Git 관리 가능 (사용자 교육 및 계정 정책 필요)
